\documentclass[a4paper]{scrreprt}

\usepackage[utf8]{inputenc}
\usepackage{polski}

\usepackage{enumitem}
\usepackage[bookmarks=true]{hyperref}

\hypersetup{
    pdftitle={Specyfikacja Wymagań Trend Spotter},
    pdfauthor={Marek Smolarczyk},
}

\def\version{1.2}

\begin{document}

\thispagestyle{empty}
\begin{flushright}\begin{bfseries}
	\Huge Specyfikacja Wymagań\\
	\vspace{1.5cm}
	\huge dla systemu\\
	\vspace{1.5cm}
	\Huge Trend Spotter\\
	\vfill
	\LARGE Wersja \version\\
\end{bfseries}\end{flushright}

\newpage

\section*{Historia Wersji}

\begin{center}
    \begin{tabular}{|c|c|c|p{6cm}|}
        \hline
	    \textbf{Wersja} & \textbf{Data} & \textbf{Autor / Autorzy} & \multicolumn{1}{|c|}{\textbf{Opis}}\\
        \hline
	    1.0 & 12.03.2018 & Marek Smolarczyk & Struktura dokumentu i podstawowe wymagania\\
        \hline
	    1.1 & 19.03.2018 & Miron Szewczyk & Specyfikacja wymagań\\
	    \hline
	    1.2 & 26.03.2018 & Michał Pawłowski & Kilka poprawek\\
        \hline
    \end{tabular}
\end{center}
\vspace{1cm}

\section*{Zespół}
\begin{enumerate}
	\itemsep-0.1cm
    \item Marek Smolarczyk (386007)
    \item Miron Szewczyk (383504)
    \item Michał Pawłowski (371303)
    \item Bartek Wrona (386389)
\end{enumerate}

\newpage

\section*{Opis ogólny}
System ma umożliwiać wykrywanie kształtujących się trendów i analizę historii popularności różnych tematów w serwisach internetowych. Z systemu będą mogli korzystać zarówno klienci indywidualni jak i firmy, i organizacje.\\
Na system składają się serwer WWW oraz crawler.

\section*{Założenia i zależności}
\begin{enumerate}
	\itemsep-0.1cm
	\item System może gromadzić anonimowe informacje o sposobie użytkowania aplikacji.
    \item System wymaga rejestracji w usłudze.
    \item System gwarantuje prawidłowe działanie aplikacji na przeglądarkach:
        \begin{enumerate}[label=\textbullet]
	        \itemsep-0.1cm
	        \item Firefox (min. wersja $\cdot$),
	        \item Chrome (min. wersja $\cdot$).
        \end{enumerate}
\end{enumerate}

\section*{Wymagania funkcjonalne}
Aplikacja będzie umożliwiała korzystanie z przetworzonych danych zgromadzonych przez crawlera w następujące sposoby:
\begin{enumerate}
	\itemsep-0.1cm
	\item Wyświetlanie historii popularności wpisanych przez użytkownika wyrazów lub  fraz odpowiadających zbiorom wyrazów.
	\item Wyświetlanie najpopularniejszych zapytań użytkowników.
	\item Wyświetlanie wyrazów, fraz szybko zyskujących na popularności (podczas wyliczania ogólnych statystyk pomijane są wyrazy z wcześniej przygotowanej listy, na przykład spójniki). % Czy ten komentarz o statystykach powinien być w wymaganiach funkcjonalnych?
\end{enumerate}
Dodatkowo użytkownik będzie miał możliwość:	
\begin{enumerate}
	\setcounter{enumi}{3}
	\itemsep-0.1cm
	\item Ograniczania zapytań do poszczególnych serwisów, poprzez wybór jednego lub wielu serwisów z rozwijanej listy.
	\item Wyświetlenia wszystkich lub części komentarzy spełniających jego kryteria wyszukiwania.
    \item Włączenia za pomocą checkboxa ignorowania polskich znaków w danym zapytaniu.
    \item Włączenia za pomocą checkboxa ignorowania wielkich liter w danym zapytaniu.
\end{enumerate}
Pozostałe wymagania:
\begin{enumerate}
	\setcounter{enumi}{7}
	\itemsep-0.1cm
	\item Korzystanie z aplikacji  wymaga zarejestrowania i zalogowania w serwisie.  Możliwa jest rejestracja za pomocą kont Facebook i Gmail.
	\item Dla każdego użytkownika jest przetrzymywana historia jego zapytań. Jest możliwe ponowne wykorzystanie dawnych zapytań poprzez wybranie ich z listy.
\end{enumerate}

\section*{Wymagania niefunkcjonalne}
\begin{enumerate}
	\itemsep-0.1cm
	\item Crawler  obsługuje maksymalnie 10 serwisów. Dane zebrane przez crawler'a są przechowywane w bazie danych nie dłużej niż 6 miesięcy.

	\item Dane przechowywane przez system  są związane z użytkownikami, tak więc jest koniecznie szyfrowane.

	\item System zapewnia obsługę pojedynczego zapytania użytkownika średnio w nie więcej niż 5 sekund.

	\item System  umożliwia jednoczesne płynne korzystanie z usługi przez nie więcej niż 10 użytkowników.

	\item System zapewnia średni czas pomiędzy awariami nie krótszy niż 2000 godzin oraz średni czas naprawy około 12 godzin.
	
	\item Przetrzymywane jest tylko pierwsze 8000 znaków każdego zebranego komentarza.
	
	\item Baza danych jest odporna na ataki typu SQL-injection.
	
	\item Każda strona jest crawlowana niezależnie. Żadna crawlowana strona nie dostanie od crawlera więcej niż jednego zapytania na sekundę.
	
	\item Administrator aplikacji ma opcje wymuszenia na crawlerze przejrzenia całej strony. Czynność ta jest bardzo czasochłonna i może zająć do tygodnia.
	
	\item Działanie crawlera opiera się na powracaniu pod wybrane linki z częstotliwością zależącą od dat zebranych pod nimi komentarzy. Im nowsza strona i im częściej pojawiają się na niej komentarze, tym częściej crawler tam wraca.
	
	\item W bazie danych przetrzymywane są komentarze wraz z datą ich napisania, datą ich zaindeksowania przez crawlera i linkiem, pod jakim zostały znalezione.
	
	\item Komentarze są przetrzymywane w bazie danych za pomocą kodowania UTF8.
	
	\item Średni czas od powstania komentarza do jego zaindeksowania jest nie większy niż 24h.
	
	\item Wymagania graficzne aplikacji (wraz z przykładami) opisane są w pliku {$\ldots$} .
	

\end{enumerate}



\end{document}
